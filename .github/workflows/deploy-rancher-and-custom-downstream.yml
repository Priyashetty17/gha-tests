name: Provision Rancher HA and Custom Downstream RKE2

on:
  workflow_dispatch:
    inputs:
      rancher_hostname_prefix:
        description: 'Prefix to use for Rancher'
        default: 'testcluster'
      rancher_helm_url:
        description: 'URL for the Rancher Helm chart repository'
        required: false
        default: 'https://releases.rancher.com/server-charts/'
      rancher_helm_repo:
        description: 'Rancher Helm Repository'
        required: false
        default: 'latest'
      rancher_chart_version:
        description: 'Rancher version to install (e.g., 2.12.0)'
        required: true
      rancher_image_tag:
        description: 'Image tag for the Rancher Helm chart (e.g., head, v2.11-head, v2.12-head)'
        required: false
        default: ''
      kubernetes_version: 
        description: 'Kubernetes version for RKE2 (e.g., v1.32.7+rke2r1)'
        default: 'v1.32.7+rke2r1'
      cert_manager_version: 
        description: 'Cert manager version (e.g., v1.17.3)'
        default: 'v1.17.3'
      rancher_terraform_provider_version:
        description: 'Version of the rancher2 Terraform provider to use (e.g., 8.0.0 if the rancher version is v2.12.0)'
        required: true
        default: '8.0.0'

env:
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  RANCHER_ADMIN_PASSWORD: ${{ secrets.RANCHER_ADMIN_PASSWORD }}
  SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
  AWS_REGION: "us-east-2"
  AWS_AMI: "ami-012fd49f6b0c404c7"
  AWS_SUBNET: "subnet-ee8cac86"
  AWS_VPC: "vpc-bfccf4d7"
  AWS_SECURITY_GROUP: "sg-04f28c5d02555da26"
  AWS_INSTANCE_TYPE: "t3a.xlarge"
  AWS_VOLUME_SIZE: 100
  KUBECONFIG: /tmp/kubeconfig-${{ github.event.inputs.rancher_hostname_prefix }}.yaml
  AWS_VOLUME_TYPE: "gp3"
  
jobs:
  provision:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    name: Provision Rancher HA and Downstream RKE2
    
    outputs:
      ssh-key-name: ${{ steps.provision-cluster.outputs.ssh-key-name }}
      fqdn-main-node: ${{ steps.provision-cluster.outputs.fqdn-main-node }}
      all-node-public-dns: ${{ steps.provision-cluster.outputs.all-node-public-dns }}
      tf-state-dir: ${{ steps.provision-cluster.outputs.tf-state-dir }}
      tf-state-dir-ds: ${{ steps.provision-ds-node.outputs.tf-state-dir-ds }}
      downstream-ip: ${{ steps.provision-ds-node.outputs.downstream-ip }}
      api-key: ${{ steps.rancher-token.outputs.api-key }}
    
    env:
      TF_MODULES_PATH: ${{ github.workspace }}/infra

    steps:
      - name: Checkout self
        uses: actions/checkout@v4

      - name: Checkout QA infra repo
        uses: actions/checkout@v4
        with:
          repository: rancher/qa-infra-automation
          path: infra

      - name: Install dependencies (Tofu, Ansible, Helm, kubectl, yq, Python)
        run: |
          sudo apt-get update
          sudo apt-get install -y unzip jq python3-pip ansible curl wget git python3-venv
          pip3 install --user pipx
          python3 -m pipx ensurepath
          pipx install ansible-core
          pipx inject ansible-core kubernetes boto3 python-terraform python-hcl2
          
          # Install OpenTofu
          TOFU_VERSION=$(curl -s https://api.github.com/repos/opentofu/opentofu/releases/latest | jq -r '.tag_name')
          TOFU_VER_CLEAN=${TOFU_VERSION#v}
          wget https://github.com/opentofu/opentofu/releases/download/${TOFU_VERSION}/tofu_${TOFU_VER_CLEAN}_linux_amd64.tar.gz
          tar -xzf tofu_${TOFU_VER_CLEAN}_linux_amd64.tar.gz
          sudo mv tofu /usr/local/bin/
          sudo ln -s /usr/local/bin/tofu /usr/local/bin/terraform
          
          # Helm
          curl -s https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          
          # kubectl
          curl -LO "https://dl.k8s.io/release/$(curl -Ls https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl && sudo mv kubectl /usr/local/bin
          
          # yq
          sudo wget https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -O /usr/local/bin/yq
          sudo chmod +x /usr/local/bin/yq

      - name: Install Ansible Collections
        run: |
          PYTHON_VERSION=$(python3 -c "import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}')")
          PYTHON_USER_BASE=$(python3 -m site --user-base)
          COLLECTION_INSTALL_PATH="$PYTHON_USER_BASE/lib/python$PYTHON_VERSION/site-packages/ansible_collections"
          
          mkdir -p "$COLLECTION_INSTALL_PATH"
          echo "Attempting to install collections to: $COLLECTION_INSTALL_PATH"

          echo "Ansible --version for collection install:"
          ansible --version 

          ANSIBLE_COLLECTIONS_PATH="$COLLECTION_INSTALL_PATH" ansible-galaxy collection install \
            community.general \
            community.aws \
            cloud.terraform \
            -p "$COLLECTION_INSTALL_PATH" \
            --force

          echo "Verifying installation:"
          ANSIBLE_COLLECTIONS_PATH="$COLLECTION_INSTALL_PATH" ansible-galaxy collection list

          LOOKUP_FILE="$COLLECTION_INSTALL_PATH/cloud/terraform/plugins/lookup/tf_output.py"
          echo "Checking for lookup plugin file at standard path: $LOOKUP_FILE"
          ls -l "$LOOKUP_FILE" || { echo "ERROR: tf_output.py not found at expected path after install. Collection may not be properly installed."; exit 1; }

          echo "ANSIBLE_COLLECTIONS_PATH=$COLLECTION_INSTALL_PATH" >> $GITHUB_ENV

      - name: Generate Unique Prefix
        id: generate-prefix  
        run: |
          UNIQUE_ID=$(uuidgen | cut -c1-8)
          UNIQUE_PREFIX="${{ github.event.inputs.rancher_hostname_prefix }}-$UNIQUE_ID"
          echo "Generated unique prefix: $UNIQUE_PREFIX"
          echo "prefix=$UNIQUE_PREFIX" >> $GITHUB_OUTPUT

      - name: Provision RKE2 HA Cluster Infrastructure with Tofu
        id: provision-cluster
        run: |
          set -x

          echo "Starting Tofu Provisioning Step..."
          cd ${{ env.TF_MODULES_PATH }}/tofu/aws/
          mkdir -p .tmp_cluster_config
          cd .tmp_cluster_config
          echo "Created Tofu working directory: $(pwd)"

          echo "Generating SSH key pair from secret..."
          mkdir -p keys
          echo "$SSH_PRIVATE_KEY" > keys/id_rsa
          chmod 600 keys/id_rsa
          ssh-keygen -y -f keys/id_rsa > keys/id_rsa.pub
          echo "Public key generated at keys/id_rsa.pub"
          
          echo "Generating Tofu main.tf and terraform.tfvars files..."
          cat <<'EOF' > main.tf
          data "aws_route53_zone" "selected" {
            name = "qa.rancher.space."
            private_zone = false
          }

          provider "aws" {
            access_key = var.aws_access_key
            secret_key = var.aws_secret_key
            region     = var.aws_region
          }

          resource "aws_key_pair" "ssh_public_key" {
            key_name   = "tf-key-${var.rancher_hostname_prefix}"
            public_key = file("keys/id_rsa.pub")
          }

          resource "aws_instance" "node" {
            for_each                    = toset(["master", "worker1", "worker2"])
            ami                         = var.aws_ami
            instance_type               = var.aws_instance_type
            key_name                    = aws_key_pair.ssh_public_key.key_name
            vpc_security_group_ids      = [var.aws_security_group]
            subnet_id                   = var.aws_subnet
            associate_public_ip_address = true

            ebs_block_device {
              device_name           = "/dev/sda1"
              volume_size           = var.aws_volume_size
              volume_type           = var.aws_volume_type
              encrypted             = true
              delete_on_termination = true
            }

            tags = {
              Name = "tf-${var.rancher_hostname_prefix}-${each.key}"
            }
          }

          resource "aws_lb" "aws_nlb" {
            internal           = false
            load_balancer_type = "network"
            subnets            = [var.aws_subnet]
            name               = "${var.rancher_hostname_prefix}-nlb"
          }

          resource "aws_lb_target_group" "rke2_tg" {
            for_each = toset(["443", "80", "9345", "6443"])
            name = "${var.rancher_hostname_prefix}-tg-${each.key}"
            port = each.key
            protocol    = "TCP"
            vpc_id      = var.aws_vpc

            health_check {
              protocol            = "HTTP"
              port                = "6443"
              path                = "/ping"
              interval            = 10
              timeout             = 6
              healthy_threshold   = 3
              unhealthy_threshold = 3
            }
          }

          resource "aws_lb_listener" "rke2_listener" {
            for_each          = aws_lb_target_group.rke2_tg
            load_balancer_arn = aws_lb.aws_nlb.arn
            port              = each.value.port
            protocol          = "TCP"
            default_action {
              type             = "forward"
              target_group_arn = each.value.arn
            }
          }

          resource "aws_lb_target_group_attachment" "rke2_tg_attachment" {
            for_each = {
              for pair in setproduct(keys(aws_instance.node), ["443", "80", "9345", "6443"]) :
              "${pair[0]}-${pair[1]}" => {
                instance_id = aws_instance.node[pair[0]].id
                port = pair[1]
              }
            }
            target_group_arn = aws_lb_target_group.rke2_tg[each.value.port].arn
            target_id = each.value.instance_id
            port = each.value.port
          }

          resource "aws_route53_record" "rancher_cname" {
            zone_id = data.aws_route53_zone.selected.zone_id
            name    = "${var.rancher_hostname_prefix}.qa.rancher.space"
            type    = "CNAME"
            ttl     = 300
            records = [aws_lb.aws_nlb.dns_name]
          }
          
          variable "rancher_hostname_prefix" { type = string }
          variable "aws_region" { type = string }
          variable "aws_access_key" { type = string }
          variable "aws_secret_key" { type = string }
          variable "aws_ami" { type = string }
          variable "aws_instance_type" { type = string }
          variable "aws_security_group" { type = string }
          variable "aws_subnet" { type = string }
          variable "aws_vpc" { type = string }
          variable "aws_volume_size" { type = number }
          variable "aws_volume_type" { type = string }

          output "first_node_public_dns" {
            value = aws_instance.node["master"].public_dns
          }
          output "first_node_private_ip" {
            value = aws_instance.node["master"].private_ip
          }
          output "all_node_public_dns" {
            value = [for node in aws_instance.node : node.public_dns]
          }
          output "all_instance_ids" {
            value = [for node in aws_instance.node : node.id]
          }
          output "lb_dns_name" {
            value = aws_lb.aws_nlb.dns_name
          }
          output "tf_state_dir" {
            value = path.module
          }
          output "ssh_key_name" {
            value = aws_key_pair.ssh_public_key.key_name
          }
          EOF
          
          echo "Writing terraform.tfvars file..."
          echo "rancher_hostname_prefix=\"${{ steps.generate-prefix.outputs.prefix }}\"" > terraform.tfvars
          echo "aws_region=\"$AWS_REGION\"" >> terraform.tfvars
          echo "aws_access_key=\"$AWS_ACCESS_KEY_ID\"" >> terraform.tfvars
          echo "aws_secret_key=\"$AWS_SECRET_ACCESS_KEY\"" >> terraform.tfvars
          echo "aws_ami=\"$AWS_AMI\"" >> terraform.tfvars
          echo "aws_instance_type=\"$AWS_INSTANCE_TYPE\"" >> terraform.tfvars
          echo "aws_security_group=\"$AWS_SECURITY_GROUP\"" >> terraform.tfvars
          echo "aws_subnet=\"$AWS_SUBNET\"" >> terraform.tfvars
          echo "aws_vpc=\"$AWS_VPC\"" >> terraform.tfvars
          echo "aws_volume_size=$AWS_VOLUME_SIZE" >> terraform.tfvars
          echo "aws_volume_type=\"$AWS_VOLUME_TYPE\"" >> terraform.tfvars
          
          echo "Running tofu init..."
          tofu init
          
          echo "Running tofu apply..."
          tofu apply -var-file=terraform.tfvars -auto-approve
          
          echo "Tofu apply command completed. Refreshing state to get outputs..."
          tofu refresh
          
          FIRST_NODE_PUBLIC_DNS=$(tofu output -raw first_node_public_dns || echo "")
          FIRST_NODE_PRIVATE_IP=$(tofu output -raw first_node_private_ip || echo "")
          IP_LIST=$(tofu output -json all_node_public_dns | jq -r 'join(",")')
          EC2_INSTANCE_IDS=$(tofu output -json all_instance_ids | jq -r 'join(",")')
          LB_DNS=$(tofu output -raw lb_dns_name || echo "")
          
          echo "IP_LIST=$IP_LIST" >> $GITHUB_ENV
          echo "KUBE_API_HOST_MAIN_NODE=$FIRST_NODE_PUBLIC_DNS" >> $GITHUB_ENV
          echo "FQDN_MAIN_NODE=$FIRST_NODE_PUBLIC_DNS" >> $GITHUB_ENV
          echo "FIRST_NODE_PRIVATE_IP=$FIRST_NODE_PRIVATE_IP" >> $GITHUB_ENV
          echo "EC2_INSTANCE_IDS=$EC2_INSTANCE_IDS" >> $GITHUB_ENV
          echo "LB_DNS=$LB_DNS" >> $GITHUB_ENV
          echo "fqdn-main-node=$FIRST_NODE_PUBLIC_DNS" >> $GITHUB_OUTPUT
          echo "tf-state-dir=$(pwd)" >> $GITHUB_OUTPUT
          echo "ssh-key-name=$(tofu output -raw ssh_key_name)" >> $GITHUB_OUTPUT
          
      - name: Setup Initial RKE2 Master Node with Ansible
        env:
          ANSIBLE_HOST_KEY_CHECKING: 'false'
        run: |
          cd .github/ansible/rke2-setup
          cp ${{ steps.provision-cluster.outputs.tf-state-dir }}/keys/id_rsa rke2_ha.pem
          chmod 600 rke2_ha.pem
          cp ${{ steps.provision-cluster.outputs.tf-state-dir }}/terraform.tfstate .

          FQDN_MAIN_NODE_VAR="${{ steps.provision-cluster.outputs.fqdn-main-node }}"

          echo "[rke2_master]" > hosts.ini
          echo "$FQDN_MAIN_NODE_VAR ansible_user=ubuntu ansible_ssh_private_key_file=rke2_ha.pem" >> hosts.ini
          UNIQUE_PREFIX_VAR="${{ steps.generate-prefix.outputs.prefix }}"

          ANSIBLE_VARS="kubernetes_version=${{ github.event.inputs.kubernetes_version }} unique_prefix=$UNIQUE_PREFIX_VAR rancher_hostname_prefix=$UNIQUE_PREFIX_VAR terraform_state_file=./terraform.tfstate kubeconfig_file=${{ env.KUBECONFIG }}"
          ansible-playbook -i hosts.ini rke2-master-setup.yml --extra-vars "$ANSIBLE_VARS"

      - name: Setup Joining RKE2 Master Nodes with Ansible
        env:
          ANSIBLE_HOST_KEY_CHECKING: 'false'
        run: |
          cd .github/ansible/rke2-setup
          cp ${{ steps.provision-cluster.outputs.tf-state-dir }}/keys/id_rsa rke2_ha.pem
          chmod 600 rke2_ha.pem
          cp ${{ steps.provision-cluster.outputs.tf-state-dir }}/terraform.tfstate .
          
          UNIQUE_PREFIX_VAR="${{ steps.generate-prefix.outputs.prefix }}"
          KUBE_API_HOST_VAR="${{ steps.provision-cluster.outputs.fqdn-main-node }}"
          
          IFS=',' read -ra ADDR <<< "$IP_LIST"
          echo "[rke2_join]" > hosts.ini
          for i in "${ADDR[@]:1}"; do
            echo "$i ansible_user=ubuntu ansible_ssh_private_key_file=rke2_ha.pem" >> hosts.ini
          done

          ANSIBLE_VARS="unique_prefix=$UNIQUE_PREFIX_VAR rancher_hostname_prefix=$UNIQUE_PREFIX_VAR kube_api_host=$KUBE_API_HOST_VAR kubernetes_version=${{ github.event.inputs.kubernetes_version }} terraform_state_file=./terraform.tfstate"
          ansible-playbook -i hosts.ini rke2-join-node-setup.yml --extra-vars "$ANSIBLE_VARS"

      - name: Wait for all RKE2 nodes to be ready in the cluster
        env:
          KUBECONFIG: ${{ env.KUBECONFIG }}
        run: |
          ALL_NODES_READY=false
          RETRIES=20
          SLEEP_TIME=30

          for i in $(seq 1 $RETRIES); do
            echo "Attempt $i/$RETRIES: Checking node status with kubectl..."
            READY_NODES=$(kubectl get nodes -o json | jq -r '[.items[] | select(.status.conditions[] | .type=="Ready" and .status=="True")] | length')
            IFS=',' read -ra ALL_NODES_PUBLIC_IP <<< "$IP_LIST"
            EXPECTED_NODES=${#ALL_NODES_PUBLIC_IP[@]}
            echo "Expected nodes: $EXPECTED_NODES, Ready nodes: $READY_NODES"

            if [ "$READY_NODES" -eq "$EXPECTED_NODES" ]; then
              ALL_NODES_READY=true
              echo "✅ All $EXPECTED_NODES RKE2 nodes are ready!"
              echo "Final Cluster State:"
              kubectl get nodes -o wide
              break
            else
              echo "Still waiting for nodes to become ready. Retrying in $SLEEP_TIME seconds..."
              sleep $SLEEP_TIME
            fi
          done

          if [ "$ALL_NODES_READY" = false ]; then
            echo "❌ Timeout: Not all RKE2 nodes became ready within the allotted time."
            kubectl get nodes -o wide
            exit 1
          fi

          echo "RKE2 HA Cluster setup complete."

      - name: Strip 'v' from Rancher Chart Version
        id: strip-version
        run: |
          STRIPPED_VERSION=$(echo "${{ github.event.inputs.rancher_chart_version }}" | sed 's/^v//')
          echo "stripped-version=$STRIPPED_VERSION" >> $GITHUB_OUTPUT
          echo "Stripped Rancher version for Helm: $STRIPPED_VERSION"

      - name: Deploy Rancher on RKE2 HA cluster
        id: deploy-rancher
        run: |
          cd .github/ansible/rancher
          echo "$SSH_PRIVATE_KEY" > rancher_ha.pem
          chmod 600 rancher_ha.pem
          echo "$IP_LIST" | tr ',' '\n' > ha_nodes.txt
          awk '{ print $0 " ansible_user=ubuntu ansible_ssh_private_key_file=rancher_ha.pem" }' ha_nodes.txt > inventory.ini
          
          ansible-playbook -i inventory.ini rancher-playbook.yml \
            --extra-vars "rancher_version=${{ steps.strip-version.outputs.stripped-version }} \
              bootstrap_password=${RANCHER_ADMIN_PASSWORD} \
              kubeconfig_file=${{ env.KUBECONFIG }} \
              cert_manager_version=${{ github.event.inputs.cert_manager_version }} \
              fqdn=${{ steps.generate-prefix.outputs.prefix }}.qa.rancher.space \
              rancher_image_tag=${{ github.event.inputs.rancher_image_tag }} \
              rancher_helm_url=${{ github.event.inputs.rancher_helm_url }} \
              rancher_helm_repo=${{ github.event.inputs.rancher_helm_repo }}"

      - name: Set Rancher URL
        id: set-rancher-url
        run: |
          RANCHER_FQDN_WITH_ID="${{ steps.generate-prefix.outputs.prefix }}.qa.rancher.space"
          echo "RANCHER_FQDN=$RANCHER_FQDN_WITH_ID" >> $GITHUB_ENV
          echo "RANCHER_URL=https://${RANCHER_FQDN_WITH_ID}" >> $GITHUB_ENV
          echo "fqdn=$RANCHER_FQDN_WITH_ID" >> $GITHUB_OUTPUT
          echo "url=https://${RANCHER_FQDN_WITH_ID}" >> $GITHUB_OUTPUT

      - name: Wait for Rancher DNS to resolve
        run: |
          echo "Waiting for DNS to resolve for ${{ steps.set-rancher-url.outputs.fqdn }}"
          RETRY_COUNT=0
          MAX_RETRIES=20
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if nslookup ${{ steps.set-rancher-url.outputs.fqdn }}; then
              echo "DNS resolution successful!"
              exit 0
            else
              echo "DNS not yet resolved. Retrying in 10 seconds..."
              sleep 10
              RETRY_COUNT=$((RETRY_COUNT+1))
            fi
          done
          echo "DNS resolution timed out after $MAX_RETRIES retries."
          exit 1

      - name: Fetch Rancher API key
        id: rancher-token
        run: |
          RETRY_COUNT=0
          MAX_RETRIES=20
          SLEEP_TIME=20
          RANCHER_URL="${{ steps.set-rancher-url.outputs.url }}"

          echo "Attempting to log in to Rancher to get a Bearer token..."
          
          LOGIN_TOKEN=""
          while [ -z "$LOGIN_TOKEN" ] && [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if [ $RETRY_COUNT -gt 0 ]; then
              echo "Login failed. Retrying in $SLEEP_TIME seconds... (Attempt $((RETRY_COUNT + 1))/$MAX_RETRIES)"
              sleep $SLEEP_TIME
            fi

            login_payload='{"username":"admin","password":"'"${RANCHER_ADMIN_PASSWORD}"'"}'
            token_response=$(curl -sk -X POST \
              "${RANCHER_URL}/v3-public/localProviders/local?action=login" \
              -H 'Content-Type: application/json' \
              --data "$login_payload")
            
            if echo "$token_response" | jq -e '.token' >/dev/null; then
                LOGIN_TOKEN=$(echo "$token_response" | jq -r .token)
                echo "Successfully fetched Bearer token."
                break
            else
                echo "Rancher API not yet ready or returned invalid response."
                echo "Response received: $token_response"
                RETRY_COUNT=$((RETRY_COUNT+1))
            fi
          done

          if [ -z "$LOGIN_TOKEN" ]; then
            echo "❌ Failed to fetch Bearer token after $MAX_RETRIES retries."
            exit 1
          fi

          echo "Attempting to create a new API key with the Bearer token..."
          API_ACCESS_KEY=""
          API_SECRET_KEY=""
          RETRY_COUNT=0
          MAX_RETRIES=10
          SLEEP_TIME=10

          while [ -z "$API_ACCESS_KEY" ] && [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if [ $RETRY_COUNT -gt 0 ]; then
              echo "API key creation failed. Retrying in $SLEEP_TIME seconds... (Attempt $((RETRY_COUNT + 1))/$MAX_RETRIES)"
              sleep $SLEEP_TIME
            fi

            API_KEY_RESPONSE=$(curl -sk -X POST "${RANCHER_URL}/v3/tokens" \
              -H "Authorization: Bearer $LOGIN_TOKEN" \
              -H 'Content-Type: application/json' \
              --data '{"type":"token","description":"gha-tofu"}')

            API_ACCESS_KEY=$(echo "$API_KEY_RESPONSE" | jq -r '.accessKey')
            API_SECRET_KEY=$(echo "$API_KEY_RESPONSE" | jq -r '.secretKey')
            API_KEY=$(echo "$API_KEY_RESPONSE" | jq -r '.token')

            if [ -z "$API_KEY" ]; then
              echo "Failed to extract access/secret key from response. Response: $API_KEY_RESPONSE"
            else
              echo "Successfully created and fetched new API key."
              break
            fi
            RETRY_COUNT=$((RETRY_COUNT+1))
          done

          if [ -z "$API_KEY" ]; then
            echo "❌ Failed to create a new API key after $MAX_RETRIES retries."
            exit 1
          fi

          echo "api-access-key=$API_ACCESS_KEY" >> $GITHUB_OUTPUT
          echo "api-secret-key=$API_SECRET_KEY" >> $GITHUB_OUTPUT
          echo "api-key=$API_KEY" >> $GITHUB_OUTPUT
          echo "token=$LOGIN_TOKEN" >> $GITHUB_OUTPUT

      - name: Provision downstream RKE2 node
        id: provision-ds-node
        run: |
          set -x
          echo "Starting Tofu Provisioning step for downstream RKE2 node..."
          mkdir -p .tmp_ds_node_config
          cd .tmp_ds_node_config
          echo "Created Tofu working directory for downstream node: $(pwd)"

          TF_MODULE_SOURCE="${{ env.TF_MODULES_PATH }}/tofu/aws/modules/ec2_instance"
          TF_STATE_DIR_CLUSTER="${{ steps.provision-cluster.outputs.tf-state-dir }}"

          cat <<'EOF' > main.tf
          module "downstream_node" {
            source = var.tf_module_source

            name                      = var.name
            user_id                   = var.user_id
            ami                       = var.ami
            instance_type             = var.instance_type
            subnet_id                 = var.subnet_id
            security_group_ids        = var.security_group_ids
            ssh_key_name              = var.ssh_key_name
            ssh_key                   = var.ssh_key_path
            volume_size               = var.volume_size
            associate_public_ip       = true
          }

          variable "name" { type = string }
          variable "user_id" { type = string }
          variable "ami" { type = string }
          variable "instance_type" { type = string }
          variable "subnet_id" { type = string }
          variable "security_group_ids" { type = list(string) }
          variable "ssh_key_name" { type = string }
          variable "ssh_key_path" { type = string }
          variable "volume_size" { type = number }
          variable "tf_module_source" { type = string }
          
          output "public_dns" { value = module.downstream_node.public_dns }
          output "tf_state_dir" { value = path.module }
          EOF

          echo "Writing terraform.tfvars file..."
          DOWNSTREAM_NODE_NAME="${{ steps.generate-prefix.outputs.prefix }}-downstream-node"
          echo "name=\"$DOWNSTREAM_NODE_NAME\"" > terraform.tfvars
          echo "user_id=\"${{ steps.generate-prefix.outputs.prefix }}\"" >> terraform.tfvars
          echo "ami=\"$AWS_AMI\"" >> terraform.tfvars
          echo "instance_type=\"$AWS_INSTANCE_TYPE\"" >> terraform.tfvars
          echo "subnet_id=\"$AWS_SUBNET\"" >> terraform.tfvars
          echo "security_group_ids=[\"$AWS_SECURITY_GROUP\"]" >> terraform.tfvars
          echo "ssh_key_name=\"${{ steps.provision-cluster.outputs.ssh-key-name }}\"" >> terraform.tfvars
          echo "ssh_key_path=\"$TF_STATE_DIR_CLUSTER/keys/id_rsa\"" >> terraform.tfvars
          echo "volume_size=$AWS_VOLUME_SIZE" >> terraform.tfvars
          echo "tf_module_source=\"$TF_MODULE_SOURCE\"" >> terraform.tfvars

          echo "Running tofu init..."
          tofu init

          echo "===== terraform.tfvars ====="
          cat terraform.tfvars
          
          echo "Running tofu apply..."
          tofu apply -var-file=terraform.tfvars -auto-approve

          DOWNSTREAM_IP=$(tofu output -raw public_dns)
          TF_STATE_DIR_DS=$(tofu output -raw tf_state_dir)
          
          echo "DOWNSTREAM_IP=$DOWNSTREAM_IP" >> $GITHUB_ENV
          echo "Downstream node public DNS: $DOWNSTREAM_IP"
          echo "downstream-ip=$DOWNSTREAM_IP" >> $GITHUB_OUTPUT
          echo "tf-state-dir-ds=$TF_STATE_DIR_DS" >> $GITHUB_OUTPUT

      - name: Patch Terraform Files for RKE2
        id: patch-tf-files
        run: |
          set -e
          echo "Patching Terraform files."
          
          TF_DIR="${{ env.TF_MODULES_PATH }}/tofu/rancher/custom_cluster"
          TF_MAIN_FILE="$TF_DIR/main.tf"
          RANCHER_TF_PROVIDER_VERSION="${{ github.event.inputs.rancher_terraform_provider_version }}"
          
          if [ -f "$TF_MAIN_FILE" ]; then
            echo "Original main.tf content:"
            cat "$TF_MAIN_FILE"
            
            TEMP_FILE=$(mktemp)
            printf "terraform {\n  required_providers {\n    rancher2 = {\n      source  = \"rancher/rancher2\"\n      version = \"${RANCHER_TF_PROVIDER_VERSION}\"\n    }\n  }\n}\n\n" > "$TEMP_FILE"
            sed -E '/^terraform \{/,/^\}/d' "$TF_MAIN_FILE" >> "$TEMP_FILE"
            sed -i 's/resource "rancher2_cluster"/resource "rancher2_cluster_v2"/g' "$TEMP_FILE"
            sed -i '/rkeK8sSystemImage/d' "$TEMP_FILE"
            printf "\noutput \"cluster_registration_command\" {\n  value = rancher2_cluster_v2.rancher2_cluster_v2.cluster_registration_token.0.node_command\n  sensitive = true\n}\n" >> "$TEMP_FILE"
            mv "$TEMP_FILE" "$TF_MAIN_FILE"
            
            echo "Patched main.tf content:"
            cat "$TF_MAIN_FILE"
            
            echo "TF_DIR=$TF_DIR" >> $GITHUB_OUTPUT
          else
            echo "❌ ERROR: main.tf not found at $TF_MAIN_FILE"
            exit 1
          fi
          
      - name: Custom Cluster Registration in Rancher with Tofu
        id: registration
        run: |
          set -e
          
          TF_WORKING_DIR=$(mktemp -d)
          cp -r ${{ steps.patch-tf-files.outputs.TF_DIR }}/. "$TF_WORKING_DIR"
          cd "$TF_WORKING_DIR"
          
          if [ -f "terraform.tf" ]; then
            echo "Removing conflicting terraform.tf file."
            rm terraform.tf
          fi
          
          echo "Running tofu init..."
          tofu init
          
          echo "Running tofu apply..."
          tofu apply \
            -var "fqdn=${{ steps.set-rancher-url.outputs.url }}" \
            -var "api_key=${{ steps.rancher-token.outputs.api-key }}" \
            -var "kubernetes_version=${{ github.event.inputs.kubernetes_version }}" \
            -var "generate_name=${{ steps.generate-prefix.outputs.prefix }}-downstream-rke2-cluster" \
            -auto-approve

          echo "tf-state-dir-reg=$TF_WORKING_DIR" >> $GITHUB_OUTPUT

      - name: Wait for and fetch the cluster registration command
        id: fetch-reg-command
        run: |
          set -e
          RETRY_COUNT=0
          MAX_RETRIES=20
          SLEEP_TIME=30
          RANCHER_URL="${{ steps.set-rancher-url.outputs.url }}"
          API_KEY="${{ steps.rancher-token.outputs.api-key }}"

          echo "Polling Rancher API to get the cluster registration command..."

          while [ "$RETRY_COUNT" -lt "$MAX_RETRIES" ]; do
            echo "Attempt $((RETRY_COUNT + 1))/$MAX_RETRIES..."
            set +e
            CLUSTER_ID=$(curl -sk -H "Authorization: Bearer $API_KEY" \
              "$RANCHER_URL/v1/management.cattle.io.clusters" | jq -r '.data[] | select(.id != "local") | .id' | head -n1)
            JQ_EXIT_CODE=$?
            set -e

            if [ $JQ_EXIT_CODE -ne 0 ] || [ -z "$CLUSTER_ID" ]; then
              echo "Cluster not found yet. Retrying in $SLEEP_TIME seconds..."
              sleep $SLEEP_TIME
              RETRY_COUNT=$((RETRY_COUNT+1))
              continue
            fi

            echo "Found cluster with ID: $CLUSTER_ID"

            echo "Triggering cluster update to refresh registration command..."
            set +e
            CLUSTER_SPEC=$(curl -sk -H "Authorization: Bearer $API_KEY" "$RANCHER_URL/v1/management.cattle.io.clusters/$CLUSTER_ID" | jq '{spec}')
             set -e
            curl -sk -X PATCH -H "Authorization: Bearer $API_KEY" -H "Content-Type: application/merge-patch+json" \
              -d "$CLUSTER_SPEC" "$RANCHER_URL/v1/management.cattle.io.clusters/$CLUSTER_ID" >/dev/null

            sleep 5

            echo "Fetch registration command..."
            set +e
            REG_COMMAND=$(curl -sk -H "Authorization: Bearer $API_KEY" "$RANCHER_URL/v1/management.cattle.io.clusterregistrationtokens/$CLUSTER_ID/default-token" \
              | jq -r '.status.insecureCommand // empty')
            JQ_EXIT_CODE=$?
            set -e

            if [ $JQ_EXIT_CODE -ne 0 ] || [ -z "$REG_COMMAND" ] || [ "$REG_COMMAND" == "null" ] || [[ ! "$REG_COMMAND" =~ ^curl ]]; then
              echo "Registration command not available or malformed. Retrying in $SLEEP_TIME seconds..."
              sleep $SLEEP_TIME
              RETRY_COUNT=$((RETRY_COUNT+1))
              continue
            fi

            echo "Successfully fetched registration command."
            echo "cluster-reg-command=$REG_COMMAND" >> $GITHUB_OUTPUT
            break
          done

          if [ "$RETRY_COUNT" -eq "$MAX_RETRIES" ]; then
            echo "❌ Timeout: Failed to get the registration command after $MAX_RETRIES retries."
            exit 1
          fi

      - name: Print the registration command
        run: |
          echo "The full command is: ${{ steps.fetch-reg-command.outputs.cluster-reg-command }}"

      - name: Run registration command on downstream node with Ansible
        id: register-cluster
        env:
          ANSIBLE_HOST_KEY_CHECKING: 'false'
        run: |
          set -e
          echo "Registering the downstream node..."
          DOWNSTREAM_IP="${{ steps.provision-ds-node.outputs.downstream-ip }}"
          REG_COMMAND="${{ steps.fetch-reg-command.outputs.cluster-reg-command }}"

          if [ -z "$DOWNSTREAM_IP" ]; then
            echo "❌ ERROR: Downstream node IP is empty."
            exit 1
          fi

          if [ -z "$REG_COMMAND" ]; then
            echo "❌ ERROR: Cluster registration command is empty. The previous step failed to retrieve it."
            exit 1
          fi

          echo "Downstream node public DNS: $DOWNSTREAM_IP"
          echo "Registration command: $REG_COMMAND"

          echo "Setting up SSH private key for Ansible connection..."
          mkdir -p keys
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > keys/id_rsa
          chmod 600 keys/id_rsa

          ANSIBLE_INVENTORY=$(mktemp)
          echo "$DOWNSTREAM_IP ansible_user=ubuntu ansible_ssh_private_key_file=./keys/id_rsa" > "$ANSIBLE_INVENTORY"

          echo "Installing kubectl on downstream node..."
          ansible-playbook all -i "$ANSIBLE_INVENTORY" -m shell -a "\
            curl -LO \"https://dl.k8s.io/release/$(curl -Ls https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\" && \
            chmod +x kubectl && \
            sudo mv kubectl /usr/local/bin/kubectl" --become
            
          echo "Registering the downstream node..."
          ansible-playbook all -i "$ANSIBLE_INVENTORY" -m shell -a "$REG_COMMAND"
          
  cleanup:
    runs-on: ubuntu-latest
    name: Destroy Tofu Resources
    needs: provision
    if: always()

    steps:
      - name: Download Tofu state files
        uses: actions/download-artifact@v4
        with:
          name: tofu-state-files
          path: tofu-state-files

      - name: Install dependencies (Tofu)
        run: |
          sudo apt-get update
          sudo apt-get install -y unzip jq
          
          TOFU_VERSION=$(curl -s https://api.github.com/repos/opentofu/opentofu/releases/latest | jq -r '.tag_name')
          TOFU_VER_CLEAN=${TOFU_VERSION#v}
          wget -q https://github.com/opentofu/opentofu/releases/download/${TOFU_VERSION}/tofu_${TOFU_VER_CLEAN}_linux_amd64.tar.gz
          tar -xzf tofu_${TOFU_VER_CLEAN}_linux_amd64.tar.gz
          sudo mv tofu /usr/local/bin/
          sudo ln -s /usr/local/bin/tofu /usr/local/bin/terraform
      
      - name: Destroy Downstream RKE2 Node Infrastructure
        run: |
          cd tofu-state-files/tmp*/downstream_node_tofu
          echo "Destroying downstream RKE2 node infrastructure with Tofu..."
          tofu destroy -auto-approve
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.AWS_REGION }}

      - name: Destroy Rancher Registration Resources
        run: |
          cd tofu-state-files/tmp*/rancher_custom_cluster_tofu
          echo "Destroying Rancher registration resources with Tofu..."
          tofu destroy -auto-approve
        env:
          RANCHER_URL: https://${{ needs.provision.outputs.fqdn-main-node }}
          API_KEY: ${{ needs.provision.outputs.api-key }}
          INSECURE: "true"
          
      - name: Destroy Rancher Cluster Infrastructure
        run: |
          cd tofu-state-files/tmp*/rke2_ha_cluster_tofu
          echo "Destroying Rancher cluster infrastructure with Tofu..."
          tofu destroy -auto-approve
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.AWS_REGION }}